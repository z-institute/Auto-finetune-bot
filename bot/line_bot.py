import os
import json
import time
import openai
import textwrap
from dotenv import load_dotenv
from openai import OpenAI
from flask import Flask, request, abort
from linebot import LineBotApi, WebhookHandler
from linebot.exceptions import InvalidSignatureError
from linebot.models import MessageEvent, TextMessage, TextSendMessage, QuickReply, QuickReplyButton, MessageAction

load_dotenv()

app = Flask(__name__)

# Replace with your Channel Access Token
line_bot_api = LineBotApi(os.environ['LINE_ACCESS_TOKEN'])

# Replace with your Channel Secret
handler = WebhookHandler(os.environ['LINE_CHANNEL_SECRET'])

# Dictionary to store user states and messages
user_states = {}
user_data = {}
user_message_save = None


@app.route("/callback", methods=['POST'])
def callback():
    # Get X-Line-Signature header value
    signature = request.headers['X-Line-Signature']

    # Get request body as text
    body = request.get_data(as_text=True)
    app.logger.info("Request body: " + body)

    # Handle webhook body
    try:
        handler.handle(body, signature)
    except InvalidSignatureError:
        abort(400)

    return 'OK'


@handler.add(MessageEvent, message=TextMessage)
def handle_message(event):

    user_id = event.source.user_id

    # Initialize user state if not present
    if user_id not in user_states:
        user_states[user_id] = "start"
        user_data[user_id] = {'model':'gpt-3.5-turbo', 'api_key': None, 'instruction': None, 'conversation':{}, 'chat_model':['gpt-3.5-turbo', 'Back to main page'], 'chatting' : [False, None]}

    received_text = event.message.text
    response_text, quick_reply = process_user_message(user_id, received_text)

    # Send reply with quick replies if available
    text_message = TextSendMessage(text=response_text, quick_reply=quick_reply) if quick_reply else TextSendMessage(text=response_text)
    line_bot_api.reply_message(event.reply_token, text_message)


def process_user_message(user_id, received_text):
    state = user_states[user_id]

    # Respond based on user state
    if state == 'start' or received_text == 'Back to main page':
        response_text = textwrap.dedent("""
        æ­¡è¿ä½¿ç”¨ âœ¨GPT è‡ªå‹• fine-tune æ©Ÿå™¨äººï¼âœ¨ è«‹æ›´æ–° fine-tune æ‰€éœ€è³‡æ–™ï¼Œä»¥ä¸‹ç‚ºå„å€‹æŒ‡ä»¤ï¼ˆæŒ‰éµï¼‰çš„åŠŸèƒ½ \n
        ğŸŒŸBase ModelğŸŒŸ: fine-tune çš„åŸºç¤æ¨¡å‹ï¼Œé è¨­ç‚º gpt-3.5-turbo ï¼Œå¯è‡ªè¡Œæ›´æ–°ï¼ˆå¿…é ˆæ˜¯ OpenAI çš„æ¨¡å‹ï¼‰\n
        ğŸŒŸAPI KeyğŸŒŸ: OpenAI çš„ api key ï¼Œè«‹æ›´æ–°ç‚ºè‡ªå·±çš„ api key  \n
        ğŸŒŸInstructionğŸŒŸ: å’Œæ¨¡å‹èªªæ˜ä½ æƒ³è¦ fine-Tune çš„æ–¹å‘ï¼Œä¾‹å¦‚ï¼šä½ æ˜¯ä¸€ä½åœ‹æ–‡è€å¸«ï¼Œè¬›è©±éƒ½ç”¨æ–‡è¨€æ–‡ \n
        ğŸŒŸConversation datağŸŒŸ: æ›´æ–°ç”¨ä¾† fine-Tune æ¨¡å‹çš„å°è©±è³‡æ–™ï¼Œå°è©±é ˆå’Œ Instruction çš„æè¿°æœ‰é—œï¼Œæ‰æœƒæœ‰è¼ƒå¥½çš„æ•ˆæœ \n
        ğŸŒŸDelete datağŸŒŸ: åˆªé™¤å…ˆå‰æ‰€æœ‰çš„ Conversation data \n
        ğŸŒŸFine-TuneğŸŒŸ: ä»¥ä¸Šè³‡è¨Šæœé›†å®Œç•¢å°±èƒ½é»æ“Šé€²è¡Œ Fine-Tune çš„å·¥ä½œ ï¼ˆå°è©±è³‡æ–™é ˆé” 10 ç­†ä»¥ä¸Šï¼‰ï¼Œ Fine-Tune æˆåŠŸå¾Œæœƒè¿”å›æ¨¡å‹ id\n
        ğŸŒŸChat with modelğŸŒŸ: é¸æ“‡æƒ³è¦å°è©±çš„æ¨¡å‹ï¼Œæˆ–æ˜¯åœ¨ Fine-Tune å®Œç•¢å¾Œï¼Œè¼¸å…¥æ¨¡å‹ id èˆ‡æ‚¨çš„æ¨¡å‹é–‹å§‹å°è©± \n
        ğŸŒŸCheck datağŸŒŸ: æŸ¥çœ‹ä»¥ä¸Šç›®å‰æ‰€æœ‰å·²è¼¸å…¥çš„è³‡æ–™
        """)
        quick_reply = create_quick_replies(['Base Model', 'API Key', 'Instruciton', 'Conversation data', 'Delete data', 'Fine-Tune', 'Chat with model', 'Check data'])
        user_states[user_id] = 'waiting_for_action'
        
        # update data if chatting canceled
        user_data[user_id]['chatting'][0], user_data[user_id]['chatting'][1] = False, None
    
    # Update base model    
    elif state == 'waiting_for_action' and received_text == 'Base Model':
        response_text = "è«‹è¼¸å…¥æ¨¡å‹åç¨±æˆ–æ˜¯é»æ“Š gpt-3.5-turbo ç¹¼çºŒä½¿ç”¨ gpt-3.5-turbo"
        quick_reply = create_quick_replies(['gpt-3.5-turbo'])
        user_states[user_id] = 'waiting_for_model_name'
    elif state == 'waiting_for_model_name':
        response_text = "å·²æ›´æ–° Base Modelï¼ \n é»æ“Š Back to main page å›åˆ°ä¸»é "
        quick_reply = create_quick_replies(['Back to main page'])
        user_states[user_id] = 'start'
        # update data
        model_name = received_text
        user_data[user_id]['model'] = model_name
    
    # Update api key
    elif state == 'waiting_for_action' and received_text == 'API Key':
        response_text = "è«‹è¼¸å…¥ OpenAI api key \n æ³¨æ„ï¼è«‹ä¸è¦æ´©æ¼ api key \n æˆ–é»æ“Š Back to main page å›åˆ°ä¸»é "
        quick_reply = create_quick_replies(['Back to main page'])
        user_states[user_id] = 'waiting_for_api_key'
    elif state == 'waiting_for_api_key':
        response_text = "å·²æ›´æ–° api keyï¼ \n é»æ“Š Back to main page å›åˆ°ä¸»é "
        quick_reply = create_quick_replies(['Back to main page'])
        user_states[user_id] = 'start'
        # update data
        api_key = received_text
        user_data[user_id]['api_key'] = api_key

    # Update instruction
    elif state == 'waiting_for_action' and received_text == 'Instruciton':
        response_text = "è«‹è¼¸å…¥ä½ å°æ–¼æ¨¡å‹çš„æè¿°ï¼Œä¾‹ï¼šä½ æ˜¯ä¸€ä½ ... ï¼Œ å¾ˆæ“…é•·... \n æˆ–é»æ“Š Back to main page å›åˆ°ä¸»é "
        quick_reply = create_quick_replies(['Back to main page'])
        user_states[user_id] = 'waiting_for_instruction'
    elif state == 'waiting_for_instruction':
        response_text = "å·²æ›´æ–° Instructionï¼ \n é»æ“Š Back to main page å›åˆ°ä¸»é "
        quick_reply = create_quick_replies(['Back to main page'])
        user_states[user_id] = 'start'
        # update data
        instruction = received_text
        user_data[user_id]['instruction'] = instruction

    # Update conversation data
    elif (state == 'waiting_for_action' and received_text == 'Conversation data') or (state == 'waiting_for_continue_or_not' and received_text == 'Yes'):
        response_text = "è¼¸å…¥å°è©±è³‡æ–™ (ä½¿ç”¨è€…è¼¸å…¥) \n æˆ–é»æ“Š Back to main page å›åˆ°ä¸»é "
        quick_reply = create_quick_replies(['Back to main page'])
        user_states[user_id] = 'waiting_for_conversation'
    elif state == 'waiting_for_conversation':
        response_text = "è¼¸å…¥å°è©±è³‡æ–™ (å»ºè­°æ¨¡å‹æ€éº¼å›è¦†)"
        quick_reply = None
        user_states[user_id] = 'conversation_complete'
        # store user message
        global user_message_save
        user_message_save = received_text
    elif state == 'conversation_complete':
        response_text = "æƒ³è¦ç¹¼çºŒè¼¸å…¥å°è©±è³‡æ–™ï¼Ÿ \n æˆ–é»æ“Š Back to main page å›åˆ°ä¸»é "
        quick_reply = create_quick_replies(['Yes', 'Back to main page'])
        user_states[user_id] = 'waiting_for_continue_or_not'
        # update data
        assistant_message = received_text
        user_data[user_id]['conversation'][user_message_save] = assistant_message
        
    # Delete conversation data
    elif state == 'waiting_for_action' and received_text == 'Delete data':
        response_text = "æƒ³è¦åˆªé™¤å·²è¼¸å…¥çš„å°è©±è³‡æ–™å—ï¼Ÿ \n æˆ–é»æ“Š Back to main page å›åˆ°ä¸»é "
        quick_reply = create_quick_replies(['Yes', 'Back to main page'])
        user_states[user_id] = 'waiting_for_delete_or_not'
    elif state == 'waiting_for_delete_or_not' and received_text == 'Yes':
        response_text = "å·²åˆªé™¤å…ˆå‰å°è©±è³‡æ–™ \n é»æ“Š Back to main page å›åˆ°ä¸»é "
        quick_reply = create_quick_replies(['Back to main page'])
        user_states[user_id] = 'start'
        # delete data
        delete_data(user_id)

    # Fine-tune
    elif state == 'waiting_for_action' and received_text == 'Fine-Tune':
        response_text = "æƒ³è¦é–‹å§‹ Fine-Tune å—ï¼Ÿ \n æˆ–é»æ“Š Back to main page å›åˆ°ä¸»é "
        quick_reply = create_quick_replies(['Yes', 'Back to main page'])
        user_states[user_id] = 'waiting_for_finetune_or_not'
    elif state == 'waiting_for_finetune_or_not'and received_text == 'Yes':
        # check data
        save_to_json(user_id)
        is_data_complete = check_data(user_id)
        if is_data_complete:
            # start fine tune process
            fine_tuning(user_id)
            response_text = "é»æ“Š Back to main page å›åˆ°ä¸»é "
        else:
            # data incomplete
            response_text = "è³‡æ–™ä¸é½Šå…¨ï¼Œè«‹ç¹¼çºŒæ›´æ–°è³‡æ–™ \n é»æ“Š Back to main page å›åˆ°ä¸»é "
        quick_reply = create_quick_replies(['Back to main page'])
        user_states[user_id] = 'start'

    # Chat with model
    elif state == 'waiting_for_action' and received_text == 'Chat with model':
        models = user_data[user_id]['chat_model']
        response_text = "è«‹é¸æ“‡ä½ æƒ³è¦å°è©±çš„æ¨¡å‹ï¼Œæˆ–æ˜¯è¼¸å…¥æƒ³å°è©±çš„æ¨¡å‹ id \n æˆ–é»æ“Š Back to main page å›åˆ°ä¸»é "
        quick_reply = create_quick_replies(models)
        user_states[user_id] = 'waiting_for_chat_or_not'
    elif state == 'waiting_for_chat_or_not':
        response_text = "èŠå¤©æ¨¡å¼å·²å•Ÿå‹•ï¼Œç¾åœ¨èµ·ï¼Œå›è¦†ä½ çš„æ˜¯ä½ çš„æ¨¡å‹ \n å‚™è¨»ï¼šèˆ‡æ¨¡å‹å°è©±éœ€è¦ Instructionï¼Œæœƒè‡ªå‹•è¨­å®šç‚ºç›®å‰å„²å­˜çš„ Instruction \n ä½ å¯ä»¥éš¨æ™‚é»æ“Š Back to main page å›åˆ°ä¸»é ï¼Œä¸¦é—œé–‰èŠå¤©æ¨¡å¼"
        quick_reply = create_quick_replies(['Back to main page'])
        user_states[user_id] = 'chatting_with_model'
        # update data and activate model
        model = received_text
        user_data[user_id]['chatting'][0], user_data[user_id]['chatting'][1] = True, model
    elif state == 'chatting_with_model' and user_data[user_id]['chatting'][0]:
        user_message = received_text
        response_text = chat_with_model(user_id, user_message)
        quick_reply = create_quick_replies(['Back to main page'])

    # Check data
    elif state == 'waiting_for_action' and received_text == 'Check data':
        check_data(user_id)
        response_text = "é»æ“Š Back to main page å›åˆ°ä¸»é "
        quick_reply = create_quick_replies(['Back to main page'])
        user_states[user_id] = 'start'

    # To avoid unseen instructions
    else:
        response_text = "ä¸æ”¯æ´æ­¤æŒ‡ä»¤ï¼Œé»æ“Š Back to main page å›åˆ°ä¸»é "
        quick_reply = create_quick_replies(['Back to main page'])
        user_states[user_id] = 'start'

    return response_text, quick_reply


# Create quick reply buttons
def create_quick_replies(options):
    return QuickReply(items=[QuickReplyButton(action=MessageAction(label=option, text=option)) for option in options])

    
def delete_data(user_id):
    user_data[user_id]['conversation'] = {}
    try:
        os.remove(f"{user_id}_data.json")
    except FileNotFoundError:
        pass


# Save user messages to JSON file
def save_to_json(user_id):
    system_message = user_data[user_id]['instruction']
    conversation_data = user_data[user_id]['conversation']
    output_file = f"{user_id}_data.json"

    # Check if the file exists and if it contains data
    if os.path.exists(output_file) and os.path.getsize(output_file) > 0:
        with open(output_file, 'r', encoding='utf-8') as f:
            existing_data = f.readlines()
    else:
        existing_data = []
        
    # Prepare the new data to be added
    new_data = []
    for user_message, assistant_message in conversation_data.items():
        json_obj = {
                "messages":[
                    {"role":"system", "content":system_message},
                    {"role":"user", "content": user_message},
                    {"role":"assistant", "content": assistant_message}
                    ]
                }
        new_data.append(json.dumps(json_obj, ensure_ascii=False))
    
    # Combine the existing and new data
    all_data = existing_data + [entry + '\n' for entry in new_data]
    
    # Write all data back to the file
    with open(output_file, 'w', encoding='utf-8') as f:
        f.writelines(all_data)

    user_data[user_id]['conversation'] = {}
    print(f" Data extraction completed. JSONL file saved to: {output_file}")


def check_data(user_id):
    save_to_json(user_id)
    pairs = extract_user_assistant_pairs(user_id)
    pairs_to_string = format_pairs_to_string(pairs)
    # Create check list for all require data
    check_list = textwrap.dedent(f"""
    ğŸŒŸæ¨¡å‹ (Base model)ğŸŒŸ: {user_data[user_id]['model']} {'âœ… å·²å®Œæˆ' if user_data[user_id]['model'] else 'âŒ æœªå®Œæˆ'} \n
    ğŸŒŸAPI KeyğŸŒŸ: {user_data[user_id]['api_key']} {'âœ… å·²å®Œæˆ' if user_data[user_id]['api_key'] else 'âŒ æœªå®Œæˆ'} \n
    ğŸŒŸçµ¦äºˆæ¨¡å‹çš„æŒ‡ç¤º (Instruciton)ğŸŒŸ:  {user_data[user_id]['instruction']} {'âœ… å·²å®Œæˆ' if user_data[user_id]['instruction'] else 'âŒ æœªå®Œæˆ'} \n
    ğŸŒŸå·²å„²å­˜å°è©±ç­†æ•¸ (Conversation data)ğŸŒŸ: {len(pairs)} {'âœ… å·²å®Œæˆ' if len(pairs) >= 10 else 'âŒ æœªå®Œæˆ'} \n
    """)
    conversations = f"ç›®å‰å·²å„²å­˜çš„å°è©±è³‡æ–™ï¼š\n\n{pairs_to_string}"
    line_bot_api.push_message(user_id, TextSendMessage(text=check_list))
    line_bot_api.push_message(user_id, TextSendMessage(text=conversations))
    return True if user_data[user_id]['model'] and user_data[user_id]['api_key'] and user_data[user_id]['instruction'] and len(pairs) >= 10 else False


def extract_user_assistant_pairs(user_id):
    user_assistant_pairs = []
    json_file = f'{user_id}_data.json'

    # Open the JSON file and read line by line
    with open(json_file, 'r', encoding='utf-8') as file:
        for line in file:
            # Parse the JSON object
            data = json.loads(line)
            messages = data.get('messages', [])
            
            user_message = None
            assistant_message = None
            
            # Extract user and assistant messages
            for message in messages:
                if message['role'] == 'user':
                    user_message = message['content']
                elif message['role'] == 'assistant':
                    assistant_message = message['content']
            
            # Append the pair if both are found
            if user_message and assistant_message:
                user_assistant_pairs.append((user_message, assistant_message))
    return user_assistant_pairs


def format_pairs_to_string(pairs):
    formatted_string = ""
    
    for user, assistant in pairs:
        formatted_string += f"ä½¿ç”¨è€…è¼¸å…¥: {user}\nå»ºè­°æ¨¡å‹å›è¦†: {assistant}\n\n"
    return formatted_string.strip()


def fine_tuning(user_id):
    api = user_data[user_id]['api_key']
    client = OpenAI(api_key=api)
    model = user_data[user_id]['model']

    try:
        # Upload the training file
        response = client.files.create(
            file=open(f"{user_id}_data.json", "rb"),
            purpose='fine-tune'
            )
        training_file_id = response.id
        print(f"File uploaded successfully, file ID: {training_file_id}")

        # Start fine-tuning
        response = client.fine_tuning.jobs.create(
            training_file=training_file_id,
            model=model
            )
        fine_tune_id = response.id
        print(f"Fine-tuning started, fine-tune ID: {fine_tune_id}")
        # Send initial status to user
        fine_tune_message = f"é–‹å§‹ Fine-tune! Fine-tune ID:\n{fine_tune_id} \n æ¯åˆ†é˜æœƒå›å‚³ fine-tune ç‹€æ…‹ï¼Œè«‹è€å¿ƒç­‰å¾…ï¼"
        line_bot_api.push_message(user_id, TextSendMessage(text=fine_tune_message))

        # Monitor fine-tuning status
        while True:
            response = client.fine_tuning.jobs.retrieve(fine_tuning_job_id=fine_tune_id)
            status = response.status
            print(f"Fine-tuning status: {status}")
            # Send status update to user
            status_message = f"ç›®å‰ Fine-tune ç‹€æ…‹: {status}"
            line_bot_api.push_message(user_id, TextSendMessage(text=status_message))
            # Fine tune succeeded
            if status == 'succeeded':
                print("Fine-tuning succeeded.")
                fine_tuned_model = response.fine_tuned_model
                user_data[user_id]['chat_model'].append(fine_tuned_model)
                status_message = f"Fine-tune æˆåŠŸï¼ ä½ çš„ fine-tune æ¨¡å‹ id: {fine_tuned_model}"
                line_bot_api.push_message(user_id, TextSendMessage(text=status_message))
                break
            # Fine tune failed
            elif status == 'failed':
                print("Fine-tuning failed.")
                status_message = f"Fine-tune å¤±æ•— QQ"
                line_bot_api.push_message(user_id, TextSendMessage(text=status_message))
                break
            time.sleep(60)  # Wait for 1 minute before checking the status again
    # error 
    except openai.OpenAIError as e:
        print(f"An error occurred: {e}")
        status_message = f"Fine-tune éŒ¯èª¤ï¼è«‹ç¢ºèªè³‡æ–™æ˜¯å¦æœ‰èª¤(æ¨¡å‹åç¨±ã€API Key)"
        line_bot_api.push_message(user_id, TextSendMessage(text=status_message))


def chat_with_model(user_id, user_message):
    try:
        api = user_data[user_id]['api_key']
        client = OpenAI(api_key=api)
        
        model = user_data[user_id]['chatting'][1]
        system_message = user_data[user_id]['instruction']
        completion = client.chat.completions.create(
            model=model,
            messages=[
                {'role':'system', 'content':system_message},
                {'role': 'user', 'content': user_message}
            ]
        )
        reply_message = completion.choices[0].message.content
        return reply_message
    except openai.APIError as e:
        reply_message = "å°è©±å‡ºéŒ¯ï¼Œè«‹ç¢ºèªè³‡æ–™æ˜¯å¦æœ‰èª¤(æ¨¡å‹åç¨±ã€API Key) \n é»æ“Š Back to main page å›åˆ°ä¸»é "
        return reply_message

if __name__ == "__main__":
    app.run(debug=True)
